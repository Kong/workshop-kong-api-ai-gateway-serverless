<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="Semantic caching enhances data retrieval efficiency by focusing on the meaning or context of queries rather than just exact matches. It stores responses based on the underlying intent and semantic similarities between different queries and can then retrieve those cached queries when a similar request is made.
When a new request is made, the system can retrieve and reuse previously cached responses if they are contextually relevant, even if the phrasing is different. This method reduces redundant processing, speeds up response times, and ensures that answers are more relevant to the user’s intent, ultimately improving overall system performance and user experience.">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="AI Semantic Cache :: API Management with Kong Konnect">
    <meta name="twitter:description" content="Semantic caching enhances data retrieval efficiency by focusing on the meaning or context of queries rather than just exact matches. It stores responses based on the underlying intent and semantic similarities between different queries and can then retrieve those cached queries when a similar request is made.
When a new request is made, the system can retrieve and reuse previously cached responses if they are contextually relevant, even if the phrasing is different. This method reduces redundant processing, speeds up response times, and ensures that answers are more relevant to the user’s intent, ultimately improving overall system performance and user experience.">
    <meta property="og:url" content="http://localhost:1313/20-observability/17-use-cases/156-semantic-cache/index.html">
    <meta property="og:site_name" content="API Management with Kong Konnect">
    <meta property="og:title" content="AI Semantic Cache :: API Management with Kong Konnect">
    <meta property="og:description" content="Semantic caching enhances data retrieval efficiency by focusing on the meaning or context of queries rather than just exact matches. It stores responses based on the underlying intent and semantic similarities between different queries and can then retrieve those cached queries when a similar request is made.
When a new request is made, the system can retrieve and reuse previously cached responses if they are contextually relevant, even if the phrasing is different. This method reduces redundant processing, speeds up response times, and ensures that answers are more relevant to the user’s intent, ultimately improving overall system performance and user experience.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Observability">
    <meta itemprop="name" content="AI Semantic Cache :: API Management with Kong Konnect">
    <meta itemprop="description" content="Semantic caching enhances data retrieval efficiency by focusing on the meaning or context of queries rather than just exact matches. It stores responses based on the underlying intent and semantic similarities between different queries and can then retrieve those cached queries when a similar request is made.
When a new request is made, the system can retrieve and reuse previously cached responses if they are contextually relevant, even if the phrasing is different. This method reduces redundant processing, speeds up response times, and ensures that answers are more relevant to the user’s intent, ultimately improving overall system performance and user experience.">
    <meta itemprop="wordCount" content="1753">
    <title>AI Semantic Cache :: API Management with Kong Konnect</title>
    <link href="/css/auto-complete/auto-complete.min.css?1755093225" rel="stylesheet">
    <script src="/js/auto-complete/auto-complete.min.js?1755093225" defer></script>
    <script src="/js/search-lunr.js?1755093225" defer></script>
    <script src="/js/search.js?1755093225" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/searchindex.en.js?1755093225";
    </script>
    <script src="/js/lunr/lunr.min.js?1755093225" defer></script>
    <script src="/js/lunr/lunr.stemmer.support.min.js?1755093225" defer></script>
    <script src="/js/lunr/lunr.multi.min.js?1755093225" defer></script>
    <script src="/js/lunr/lunr.en.min.js?1755093225" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/fonts/fontawesome/css/fontawesome-all.min.css?1755093225" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/fonts/fontawesome/css/fontawesome-all.min.css?1755093225" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar/perfect-scrollbar.min.css?1755093225" rel="stylesheet">
    <link href="/css/theme.css?1755093225" rel="stylesheet">
    <link href="/css/format-html.css?1755093225" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/20-observability\/17-use-cases\/156-semantic-cache\/index.html';
      window.relearn.relBasePath='..\/..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'blue' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/20-observability/17-use-cases/156-semantic-cache/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#how-it-works">How it works</a></li>
        <li><a href="#redis-as-a-vector-database">Redis as a Vector database</a></li>
        <li><a href="#apply-the-semantic-cache-plugin">Apply the Semantic Cache plugin</a></li>
        <li><a href="#check-redis">Check Redis</a></li>
      </ul>
    </li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/index.html"><span itemprop="name">API Management with Kong Konnect</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/20-observability/index.html"><span itemprop="name">Observability</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/20-observability/17-use-cases/index.html"><span itemprop="name">Use Cases</span></a><meta itemprop="position" content="3">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">AI Semantic Cache</span><meta itemprop="position" content="4"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/20-observability/17-use-cases/155-request-response-transformer/index.html" title="AI Request and Response Transfomers (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/20-observability/17-use-cases/157-apikey/index.html" title="Key Auth (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable 20-observability" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="ai-semantic-cache">AI Semantic Cache</h1>

<p>Semantic caching enhances data retrieval efficiency by focusing on the meaning or context of queries rather than just exact matches. It stores responses based on the underlying intent and semantic similarities between different queries and can then retrieve those cached queries when a similar request is made.</p>
<p>When a new request is made, the system can retrieve and reuse previously cached responses if they are contextually relevant, even if the phrasing is different. This method reduces redundant processing, speeds up response times, and ensures that answers are more relevant to the user’s intent, ultimately improving overall system performance and user experience.</p>
<p>For example, if a user asks, “how to integrate our API with a mobile app” and later asks, “what are the steps for connecting our API to a smartphone application?”, the system understands that both questions are asking for the same information. It can then retrieve and reuse previously cached responses, even if the wording is different. This approach reduces processing time and speeds up responses.</p>
<p>The <strong>AI Semantic Cache</strong> plugin may not be ideal for you if:</p>
<ul>
<li>If you have limited hardware or budget. Storing semantic vectors and running similarity searches require a lot of storage and computing power, which could be an issue.</li>
<li>If your data doesn’t rely on semantics, or exact matches work fine, semantic caching may offer little benefit. Traditional or keyword-based caching might be more efficient.</li>
</ul>
<h3 id="how-it-works">How it works</h3>
<p>The diagram below illustrates the semantic caching mechanism implemented by the <strong>AI Semantic Cache</strong> plugin.</p>
<p><a href="#R-image-74dd971d37a2bb7cbecb4c39ea5e6465" class="lightbox-link"><img alt="semantic_cache_plugin" class="lazy lightbox figure-image" loading="lazy" src="/static/images/semantic_cache_plugin.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-74dd971d37a2bb7cbecb4c39ea5e6465"><img alt="semantic_cache_plugin" class="lazy lightbox lightbox-image" loading="lazy" src="/static/images/semantic_cache_plugin.png"></a></p>
<p>The process involves three parts: request handling, embedding generation, and response caching.</p>
<ul>
<li>First, a user starts a chat request with the LLM. The <strong>AI Semantic Cache</strong> plugin queries the vector database to see if there are any semantically similar requests that have already been cached. If there is a match, the vector database returns the cached response to the user.</li>
<li>If there isn’t a match, the <strong>AI Semantic Cache</strong> plugin prompts the embeddings LLM to generate an embedding for the response.</li>
<li>The <strong>AI Semantic Cache</strong> plugin uses a vector database and cache to store responses to requests. The plugin can then retrieve a cached response if a new request matches the semantics of a previous request, or it can tell the vector database to store a new response if there are no matches.</li>
</ul>
<p>With the <strong>AI Semantic Cache plugin</strong>, you can configure a cache of your choice to store the responses from the LLM. Currently, the plugin supports <strong>Redis</strong> as a cache.</p>
<h3 id="redis-as-a-vector-database">Redis as a Vector database</h3>
<p>We are going to configure the <strong>AI Semantic Cache</strong> to consume the Redis deployment available in the EKS Cluster. Redis, this time, will play the Vector database role.</p>
<h3 id="apply-the-semantic-cache-plugin">Apply the Semantic Cache plugin</h3>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>cat &gt; ai-semantic-cache.yaml &lt;&lt; &#39;EOF&#39;
_format_version: &#34;3.0&#34;
_info:
  select_tags:
  - semantic-cache
  - llm
_konnect:
  control_plane_name: kong-workshop
services:
- name: service1
  host: localhost
  port: 32000
  routes:
  - name: ollama-route
    paths:
    - /ollama-route
    plugins:
    - name: ai-proxy
      instance_name: ai-proxy-ollama
      config:
        route_type: llm/v1/chat
        model:
          provider: llama2
          name: llama3.2:1b
          options:
            llama2_format: ollama
            upstream_url: http://ollama.ollama:11434/api/chat
  - name: openai-route
    paths:
    - /openai-route
    plugins:
    - name: ai-proxy
      instance_name: ai-proxy-openai
      enabled: true
      config:
        route_type: llm/v1/chat
        auth:
          header_name: Authorization
          header_value: Bearer ${{ env &#34;DECK_OPENAI_API_KEY&#34; }}
        model:
          provider: openai
          name: gpt-4.1
          options:
            temperature: 1.0
    - name: ai-semantic-cache
      instance_name: ai-semantic-cache-openai
      enabled: true
      config:
        embeddings:
          auth:
            header_name: Authorization
            header_value: Bearer ${{ env &#34;DECK_OPENAI_API_KEY&#34; }}
          model:
            provider: openai
            name: &#34;text-embedding-3-small&#34;
        vectordb:
          dimensions: 1024
          distance_metric: cosine
          strategy: redis
          threshold: 0.2
          redis:
            host: &#34;redis-stack.redis.svc.cluster.local&#34;
            port: 6379
EOF</code></pre></div>
<p>Apply the declaration with decK:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>deck gateway reset --konnect-control-plane-name kong-workshop --konnect-token $PAT -f
deck gateway sync --konnect-token $PAT ai-semantic-cache.yaml</code></pre></div>
<h3 id="check-redis">Check Redis</h3>
<p>Before sending request, you can scan the Redis database:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>kubectl exec -it $(kubectl get pod -n redis -o json | jq -r &#39;.items[].metadata.name&#39;) -n redis -- redis-cli --scan</code></pre></div>
<h5 id="1st-request">1st Request</h5>
<p>Since we don&rsquo;t have any cached data, the first request is going to return &ldquo;Miss&rdquo;:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>curl -i -X POST \
  --url $DATA_PLANE_LB/openai-route \
  --header &#39;Content-Type: application/json&#39; \
   --data &#39;{
   &#34;messages&#34;: [
     {
       &#34;role&#34;: &#34;user&#34;,
       &#34;content&#34;: &#34;Who is Jimi Hendrix?&#34;
     }
   ]
 }&#39;</code></pre></div>
<ul>
<li>Expected response</li>
</ul>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>HTTP/1.1 200 OK
Content-Type: application/json
Connection: keep-alive
X-Cache-Status: Miss
x-ratelimit-limit-tokens: 30000
x-ratelimit-remaining-requests: 499
Date: Tue, 12 Aug 2025 14:47:48 GMT
x-ratelimit-remaining-tokens: 29993
access-control-expose-headers: X-Request-ID
openai-organization: user-4qzstwunaw6d1dhwnga5bc5q
openai-processing-ms: 7218
x-ratelimit-reset-requests: 120ms
openai-project: proj_r4KYFyenuGWthS5te4zaurNN
cf-cache-status: DYNAMIC
openai-version: 2020-10-01
Server: cloudflare
X-Content-Type-Options: nosniff
x-envoy-upstream-service-time: 7420
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
CF-RAY: 96e0c4e97b364d3b-GRU
x-ratelimit-limit-requests: 500
x-request-id: req_ae7f43291824451dbfec2a27b1a3ec2a
x-ratelimit-reset-tokens: 14ms
alt-svc: h3=&#34;:443&#34;; ma=86400
X-Kong-LLM-Model: openai/gpt-4.1
Content-Length: 2005
X-Kong-Upstream-Latency: 8820
X-Kong-Proxy-Latency: 876
Via: 1.1 kong/3.11.0.2-enterprise-edition
X-Kong-Request-Id: 8fd73d1623140f675ed93b0dcb4aeb16

{
  &#34;id&#34;: &#34;chatcmpl-C3kZpdNpSx8eaIHhsLg14RhZgFBww&#34;,
  &#34;object&#34;: &#34;chat.completion&#34;,
  &#34;created&#34;: 1755010061,
  &#34;model&#34;: &#34;gpt-4.1-2025-04-14&#34;,
  &#34;choices&#34;: [
    {
      &#34;index&#34;: 0,
      &#34;message&#34;: {
        &#34;role&#34;: &#34;assistant&#34;,
        &#34;content&#34;: &#34;**Jimi Hendrix** (full name: James Marshall Hendrix, born November 27, 1942 – died September 18, 1970) was an American guitarist, singer, and songwriter, widely regarded as one of the most influential electric guitarists in the history of popular music. Emerging in the late 1960s, Hendrix revolutionized the way the guitar was played, using feedback, distortion, and an array of innovative techniques that transformed rock, blues, and psychedelic music.\n\nHendrix rose to fame with his band, **The Jimi Hendrix Experience**, delivering classic albums such as *Are You Experienced* (1967) and *Electric Ladyland* (1968). His groundbreaking performances included a legendary rendition of \&#34;The Star-Spangled Banner\&#34; at Woodstock in 1969.\n\nDespite his career only spanning about four years, Hendrix&#39;s influence endures through his recordings and his impact on generations of musicians. He was posthumously inducted into the Rock and Roll Hall of Fame in 1992. Some of his most famous songs include \&#34;Purple Haze,\&#34; \&#34;Hey Joe,\&#34; \&#34;Voodoo Child (Slight Return),\&#34; and \&#34;All Along the Watchtower.\&#34; Hendrix died at the age of 27, becoming one of the most iconic members of the so-called \&#34;27 Club.\&#34;&#34;,
        &#34;refusal&#34;: null,
        &#34;annotations&#34;: []
      },
      &#34;logprobs&#34;: null,
      &#34;finish_reason&#34;: &#34;stop&#34;
    }
  ],
  &#34;usage&#34;: {
    &#34;prompt_tokens&#34;: 13,
    &#34;completion_tokens&#34;: 264,
    &#34;total_tokens&#34;: 277,
    &#34;prompt_tokens_details&#34;: {
      &#34;cached_tokens&#34;: 0,
      &#34;audio_tokens&#34;: 0
    },
    &#34;completion_tokens_details&#34;: {
      &#34;reasoning_tokens&#34;: 0,
      &#34;audio_tokens&#34;: 0,
      &#34;accepted_prediction_tokens&#34;: 0,
      &#34;rejected_prediction_tokens&#34;: 0
    }
  },
  &#34;service_tier&#34;: &#34;default&#34;,
  &#34;system_fingerprint&#34;: &#34;fp_51e1070cf2&#34;
}</code></pre></div>
<h5 id="check-redis-again">Check Redis again</h5>
<p>The Redis database has an entry now:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>kubectl exec -it $(kubectl get pod -n redis -o json | jq -r &#39;.items[].metadata.name&#39;) -n redis -- redis-cli --scan</code></pre></div>
<ul>
<li>Expected response</li>
</ul>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>&#34;kong_semantic_cache:c6dbe643-42af-421a-a094-de7735ebff12:openai-gpt-4.1:2351ee4c78c607bf3c6123e98680647d3601e1b054b783cb589e05cf3d163e36&#34;</code></pre></div>
<h5 id="2nd-request">2nd Request</h5>
<p>The Semantic Cache plugin will use the cached data for similar requests:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>curl -i -X POST \
  --url $DATA_PLANE_LB/openai-route \
  --header &#39;Content-Type: application/json&#39; \
   --data &#39;{
   &#34;messages&#34;: [
     {
       &#34;role&#34;: &#34;user&#34;,
       &#34;content&#34;: &#34;Tell me more about Jimi Hendrix&#34;
     }
   ]
 }&#39;</code></pre></div>
<ul>
<li>Expected response</li>
</ul>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>HTTP/1.1 200 OK
Date: Tue, 12 Aug 2025 14:48:55 GMT
Content-Type: application/json; charset=utf-8
Connection: keep-alive
X-Cache-Status: Hit
Age: 67
X-Cache-Key: kong_semantic_cache:c6dbe643-42af-421a-a094-de7735ebff12:openai-gpt-4.1:2351ee4c78c607bf3c6123e98680647d3601e1b054b783cb589e05cf3d163e36
X-Cache-Ttl: 233
Content-Length: 1814
X-Kong-Response-Latency: 1438
Server: kong/3.11.0.2-enterprise-edition
X-Kong-Request-Id: 2debcb5db5e6f3637bef912cca963a5d

{&#34;object&#34;:&#34;chat.completion&#34;,&#34;created&#34;:1755010061,&#34;id&#34;:&#34;2351ee4c78c607bf3c6123e98680647d3601e1b054b783cb589e05cf3d163e36&#34;,&#34;usage&#34;:{&#34;completion_tokens&#34;:264,&#34;prompt_tokens_details&#34;:{&#34;cached_tokens&#34;:0,&#34;audio_tokens&#34;:0},&#34;completion_tokens_details&#34;:{&#34;accepted_prediction_tokens&#34;:0,&#34;audio_tokens&#34;:0,&#34;rejected_prediction_tokens&#34;:0,&#34;reasoning_tokens&#34;:0},&#34;total_tokens&#34;:277,&#34;prompt_tokens&#34;:13},&#34;model&#34;:&#34;gpt-4.1-2025-04-14&#34;,&#34;service_tier&#34;:&#34;default&#34;,&#34;system_fingerprint&#34;:&#34;fp_51e1070cf2&#34;,&#34;choices&#34;:[{&#34;finish_reason&#34;:&#34;stop&#34;,&#34;index&#34;:0,&#34;logprobs&#34;:null,&#34;message&#34;:{&#34;annotations&#34;:{},&#34;role&#34;:&#34;assistant&#34;,&#34;refusal&#34;:null,&#34;content&#34;:&#34;**Jimi Hendrix** (full name: James Marshall Hendrix, born November 27, 1942 – died September 18, 1970) was an American guitarist, singer, and songwriter, widely regarded as one of the most influential electric guitarists in the history of popular music. Emerging in the late 1960s, Hendrix revolutionized the way the guitar was played, using feedback, distortion, and an array of innovative techniques that transformed rock, blues, and psychedelic music.\n\nHendrix rose to fame with his band, **The Jimi Hendrix Experience**, delivering classic albums such as *Are You Experienced* (1967) and *Electric Ladyland* (1968). His groundbreaking performances included a legendary rendition of \&#34;The Star-Spangled Banner\&#34; at Woodstock in 1969.\n\nDespite his career only spanning about four years, Hendrix&#39;s influence endures through his recordings and his impact on generations of musicians. He was posthumously inducted into the Rock and Roll Hall of Fame in 1992. Some of his most famous songs include \&#34;Purple Haze,\&#34; \&#34;Hey Joe,\&#34; \&#34;Voodoo Child (Slight Return),\&#34; and \&#34;All Along the Watchtower.\&#34; Hendrix died at the age of 27, becoming one of the most iconic members of the so-called \&#34;27 Club.\&#34;&#34;}}]}</code></pre></div>
<h5 id="3rd-request">3rd Request</h5>
<p>As expected, for a non-related request, the AI Gateway will hit the LLM to satisfy the query:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>curl -i -X POST \
  --url $DATA_PLANE_LB/openai-route \
  --header &#39;Content-Type: application/json&#39; \
   --data &#39;{
   &#34;messages&#34;: [
     {
       &#34;role&#34;: &#34;user&#34;,
       &#34;content&#34;: &#34;Who was Joseph Conrad?&#34;
     }
   ]
 }&#39;</code></pre></div>
<ul>
<li>Expected response</li>
</ul>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>HTTP/1.1 200 OK
Content-Type: application/json
Connection: keep-alive
X-Cache-Status: Miss
openai-version: 2020-10-01
x-envoy-upstream-service-time: 4746
Date: Tue, 12 Aug 2025 14:49:35 GMT
x-ratelimit-limit-requests: 500
x-ratelimit-limit-tokens: 30000
x-ratelimit-remaining-requests: 499
CF-RAY: 96e0c7a088ac1b20-GRU
x-ratelimit-remaining-tokens: 29992
alt-svc: h3=&#34;:443&#34;; ma=86400
access-control-expose-headers: X-Request-ID
X-Content-Type-Options: nosniff
Server: cloudflare
openai-organization: user-4qzstwunaw6d1dhwnga5bc5q
Strict-Transport-Security: max-age=31536000; includeSubDomains; preload
x-request-id: req_10dee9e2989e46cbb32a2125f774f446
openai-processing-ms: 4658
cf-cache-status: DYNAMIC
openai-project: proj_r4KYFyenuGWthS5te4zaurNN
x-ratelimit-reset-tokens: 16ms
x-ratelimit-reset-requests: 120ms
X-Kong-LLM-Model: openai/gpt-4.1
Content-Length: 2515
X-Kong-Upstream-Latency: 4996
X-Kong-Proxy-Latency: 2222
Via: 1.1 kong/3.11.0.2-enterprise-edition
X-Kong-Request-Id: b5fadb69431d1234d8bbd53a71abc559

{
  &#34;id&#34;: &#34;chatcmpl-C3kbbMudkoKV6rrzvOHz0lQ8IH0Ci&#34;,
  &#34;object&#34;: &#34;chat.completion&#34;,
  &#34;created&#34;: 1755010171,
  &#34;model&#34;: &#34;gpt-4.1-2025-04-14&#34;,
  &#34;choices&#34;: [
    {
      &#34;index&#34;: 0,
      &#34;message&#34;: {
        &#34;role&#34;: &#34;assistant&#34;,
        &#34;content&#34;: &#34;**Joseph Conrad** (born Józef Teodor Konrad Korzeniowski; 1857–1924) was a Polish-British writer widely regarded as one of the great novelists writing in English, despite the fact that English was not his first language. He was born in Berdychiv, in the Russian Empire (now in Ukraine), to Polish parents.\n\n**Background:**\n- **Early Life:** Conrad’s parents were exiled for their involvement in Polish independence movements. Orphaned at a young age, he spent much of his youth in Poland and later France.\n- **Seafaring Career:** In his twenties, Conrad became a merchant marine, traveling around the world and eventually settling in England. He gained British citizenship in 1886.\n\n**Literary Career:**\n- He began writing novels and short stories in English, starting with *Almayer’s Folly* (1895).\n- **Notable works** include:\n  - *Heart of Darkness* (1899)\n  - *Lord Jim* (1900)\n  - *Nostromo* (1904)\n  - *The Secret Agent* (1907)\n- His novels often deal with themes of isolation, existential doubt, imperialism, and the complexity of human nature.\n\n**Legacy:**\n- Conrad’s innovative narrative techniques and psychological depth influenced modernist literature and writers such as Virginia Woolf, T.S. Eliot, and William Faulkner.\n- *Heart of Darkness*, a novella about a journey into the Congo, is considered one of the most important works of 20th-century literature and has inspired many adaptations, including the film *Apocalypse Now*.\n\n**Summary:**  \nJoseph Conrad was a Polish-born novelist who wrote in English and became one of the leading literary figures of his time, celebrated for his adventure tales, deep psychological insight, and exploration of moral ambiguity.&#34;,
        &#34;refusal&#34;: null,
        &#34;annotations&#34;: []
      },
      &#34;logprobs&#34;: null,
      &#34;finish_reason&#34;: &#34;stop&#34;
    }
  ],
  &#34;usage&#34;: {
    &#34;prompt_tokens&#34;: 12,
    &#34;completion_tokens&#34;: 383,
    &#34;total_tokens&#34;: 395,
    &#34;prompt_tokens_details&#34;: {
      &#34;cached_tokens&#34;: 0,
      &#34;audio_tokens&#34;: 0
    },
    &#34;completion_tokens_details&#34;: {
      &#34;reasoning_tokens&#34;: 0,
      &#34;audio_tokens&#34;: 0,
      &#34;accepted_prediction_tokens&#34;: 0,
      &#34;rejected_prediction_tokens&#34;: 0
    }
  },
  &#34;service_tier&#34;: &#34;default&#34;,
  &#34;system_fingerprint&#34;: &#34;fp_799e4ca3f1&#34;
}</code></pre></div>
<h5 id="check-redis-again-1">Check Redis again</h5>
<p>Redis database has two entries now:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>kubectl exec -it $(kubectl get pod -n redis -o json | jq -r &#39;.items[].metadata.name&#39;) -n redis -- redis-cli --scan</code></pre></div>
<ul>
<li>Expected response</li>
</ul>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>&#34;kong_semantic_cache:c6dbe643-42af-421a-a094-de7735ebff12:openai-gpt-4.1:2351ee4c78c607bf3c6123e98680647d3601e1b054b783cb589e05cf3d163e36&#34;
&#34;kong_semantic_cache:c6dbe643-42af-421a-a094-de7735ebff12:openai-gpt-4.1:42aa94b4bbbedce497e59e1fd0fc617683a43b58ac7e306a47feb46f502f1499&#34;</code></pre></div>
<p>Kong-gratulations! have now reached the end of this module by authenticating the API requests with a key and associating different consumers with policy plans. You can now click <strong>Next</strong> to proceed with the next module.</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/index.html">
            <div class="logo-title">API Management with Kong Konnect</div>
          </a>
        </div>
        <search><form action="/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/index.html"><a class="padding" href="/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="" data-nav-id="/10-prerequisites/index.html"><a class="padding" href="/10-prerequisites/index.html">Prerequisites</a><ul id="R-subsections-cdc0df3ea972ffd3a9c45dea986dc8ab" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/architecture/index.html"><a class="padding" href="/architecture/index.html">Kong Konnect Architectural Overview</a></li>
            <li class="" data-nav-id="/11-konnect-setup/index.html"><a class="padding" href="/11-konnect-setup/index.html">Konnect Setup</a><ul id="R-subsections-fd457d3a7fac9b2f9cefa5c6c0dae1e7" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/12-api-gateway/index.html"><a class="padding" href="/12-api-gateway/index.html">Kong API Gateway</a><ul id="R-subsections-edeba57bcdf65a92672ecb9c5ed9177f" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/16-ai-gateway/index.html"><a class="padding" href="/16-ai-gateway/index.html">Kong AI Gateway</a><ul id="R-subsections-2f2bf218915a29de3a144cfa324a5fc4" class="collapsible-menu"></ul></li>
            <li class="parent " data-nav-id="/20-observability/index.html"><a class="padding" href="/20-observability/index.html">Observability</a><ul id="R-subsections-3829b558aa20efb46efd7e331dc0c9e9" class="collapsible-menu">
            <li class="parent alwaysopen " data-nav-id="/20-observability/17-use-cases/index.html"><a class="padding" href="/20-observability/17-use-cases/index.html">Use Cases</a><ul id="R-subsections-a063a860f8407145f89ac2776a5f4acb" class="collapsible-menu">
            <li class="" data-nav-id="/20-observability/17-use-cases/150-ai-proxy/index.html"><a class="padding" href="/20-observability/17-use-cases/150-ai-proxy/index.html">AI Proxy</a></li>
            <li class="alwaysopen " data-nav-id="/20-observability/17-use-cases/151-prompt-engineering/index.html"><a class="padding" href="/20-observability/17-use-cases/151-prompt-engineering/index.html">Prompt Engineering</a><ul id="R-subsections-dab816c1786489d1d867b2788435b5a8" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/20-observability/17-use-cases/155-request-response-transformer/index.html"><a class="padding" href="/20-observability/17-use-cases/155-request-response-transformer/index.html">AI Request and Response Transfomers</a></li>
            <li class="active " data-nav-id="/20-observability/17-use-cases/156-semantic-cache/index.html"><a class="padding" href="/20-observability/17-use-cases/156-semantic-cache/index.html">AI Semantic Cache</a></li>
            <li class="" data-nav-id="/20-observability/17-use-cases/157-apikey/index.html"><a class="padding" href="/20-observability/17-use-cases/157-apikey/index.html">Key Auth</a></li>
            <li class="" data-nav-id="/20-observability/17-use-cases/158-rate-limiting/index.html"><a class="padding" href="/20-observability/17-use-cases/158-rate-limiting/index.html">AI Rate Limiting Advanced</a></li>
            <li class="alwaysopen " data-nav-id="/20-observability/17-use-cases/159-ai-proxy-advanced/index.html"><a class="padding" href="/20-observability/17-use-cases/159-ai-proxy-advanced/index.html">AI Proxy Advanced</a><ul id="R-subsections-a3748944f54beed25e0ab521336b4101" class="collapsible-menu"></ul></li>
            <li class="" data-nav-id="/20-observability/17-use-cases/170-rag/index.html"><a class="padding" href="/20-observability/17-use-cases/170-rag/index.html">RAG - Retrieval-Augmented Generation</a></li></ul></li>
            <li class="" data-nav-id="/20-observability/210-introduction/index.html"><a class="padding" href="/20-observability/210-introduction/index.html">OpenTelemetry Introduction</a></li>
            <li class="" data-nav-id="/20-observability/220-reference_architecture/index.html"><a class="padding" href="/20-observability/220-reference_architecture/index.html">Reference Architecture</a></li>
            <li class="" data-nav-id="/20-observability/230-otel_collector_installation/index.html"><a class="padding" href="/20-observability/230-otel_collector_installation/index.html">OTel Collector Installation</a></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/js/clipboard/clipboard.min.js?1755093225" defer></script>
    <script src="/js/perfect-scrollbar/perfect-scrollbar.min.js?1755093225" defer></script>
    <script src="/js/theme.js?1755093225" defer></script>
  </body>
</html>
