<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>External Observability Stack :: API Management with Kong Konnect</title>
    <link>http://localhost:1313/20-observability/22-external/index.html</link>
    <description>The external Observability infrastructure we are going to use is based on the OpenTelemetry standard and it comprises:&#xA;OTel Collector: implements the component responsible for receiving, processing and exporting telemetry data. Loki: plays the log processing role and receiving all requests and responses processed by the Kong API and AI Gateway Data Plane. Prometheus: responsible for scraping and storing the metrics the Kong API and AI Gateway generate. Grafana: used to query and analyze logs and metrics. Jaeger: distributed tracing platform.</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="http://localhost:1313/20-observability/22-external/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reference Architecture</title>
      <link>http://localhost:1313/20-observability/22-external/220-reference_architecture/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/220-reference_architecture/index.html</guid>
      <description>The Kong Konnect and Observability Stack topology is quite simple in this example:&#xA;The main components here are:&#xA;Konnect Control Plane: responsible for administration tasks including APIs and Policies definition Konnect Data Plane: handles the requests sent by the API consumers Kong Gateway Plugins: components running inside the Data Plane to produce OpenTelemetry signals Upstream Service: services or microservices protected by the Konnnect Data Plane OpenTelemetry Collector: handles and processes the signals sent by the OTel plugin and sends them to the Dynatrace tenant Observability Stack: formed by Loki, Prometheus, Jaeger and Grafana, provides a single pane of glass with dashboards, reports, etc.</description>
    </item>
    <item>
      <title>OpenTelemetry Introduction</title>
      <link>http://localhost:1313/20-observability/22-external/222-introduction/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/222-introduction/index.html</guid>
      <description>Observability focuses mainly on three core pillars:&#xA;Logs: Detailed, timestamped records of events and activities within a system, offering a granular view of operations Metrics: Quantitative data points that capture various aspects of system performance, such as resource usage, response times, and throughput Traces: Visual paths that requests follow as they traverse through different system components, enabling end-to-end analysis of transactions and interactions OpenTelemetry Here’s a concise definition of OpenTelemetry, available on its website:</description>
    </item>
    <item>
      <title>OTel Collector Operator Installation</title>
      <link>http://localhost:1313/20-observability/22-external/223-otel_collector_operator_installation/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/223-otel_collector_operator_installation/index.html</guid>
      <description>To deploy the OpenTelemetry Collector and to get better control over it, we’re going to do it through the OpenTelemetry Kubernetes Operator. In fact, the collector is also capable of auto-instrument applications and services using OpenTelemetry instrumentation libraries.&#xA;Installing Cert-Manager The OpenTelemetry Operator requires Cert-Manager to be installed in your Kubernetes cluster. The Cert-Manager can then issue certificates to be used by the communication between the Kubernetes API Server and the existing webhook included in the operator.</description>
    </item>
    <item>
      <title>Observability Stack Installation</title>
      <link>http://localhost:1313/20-observability/22-external/224-observability_stack_installation/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/224-observability_stack_installation/index.html</guid>
      <description>Jaeger Installation We are going to use the Jaeger Helm Charts&#xA;Save the values.yaml Jaeger provides as an example:&#xA;wget -O jaeger-values.yaml https://raw.githubusercontent.com/jaegertracing/helm-charts/refs/heads/v2/charts/jaeger/values.yaml And use it to install Jaeger 2.9.0&#xA;helm install jaeger jaegertracing/jaeger -n jaeger \ --create-namespace \ --set allInOne.image.repository=jaegertracing/jaeger \ --set allInOne.image.tag=2.9.0 \ --values ./jaeger-values.yaml kubectl patch deployment jaeger -n jaeger --type json \ -p=&#39;[ {&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/readinessProbe&#34;}, {&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/spec/template/spec/containers/0/livenessProbe&#34;} ]&#39; Check Jaeger’s log with:&#xA;kubectl logs -f $(kubectl get pod -n jaeger -o json | jq -r &#39;.items[].metadata | select(.name | startswith(&#34;jaeger-&#34;))&#39; | jq -r &#39;.name&#39;) -n jaeger Prometheus Installation Add the Helm Charts repo first:</description>
    </item>
    <item>
      <title>OTel Collector and Tracing</title>
      <link>http://localhost:1313/20-observability/22-external/225-otel_collector_tracing/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/225-otel_collector_tracing/index.html</guid>
      <description>Here’s a nice introduction of OTel Collector and Jaeger deployment. The Collector is going to be running as a “remote cluster” in a specific K8s deployument.&#xA;OpenTelemetry Collector instantiation Create a collector declaration To get started we’re going to manage Traces first. Later on, we’ll enhance the collector to process both Metrics and Logs. Here’s the declaration:&#xA;cat &gt; otelcollector.yaml &lt;&lt; &#39;EOF&#39; apiVersion: opentelemetry.io/v1beta1 kind: OpenTelemetryCollector metadata: name: collector-kong namespace: opentelemetry-operator-system spec: image: otel/opentelemetry-collector-contrib:0.132.2 mode: deployment config: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 exporters: otlphttp: endpoint: http://jaeger-collector.jaeger:4318 #debug: # verbosity: detailed service: pipelines: traces: receivers: [otlp] exporters: [otlphttp] EOF The declaration has critical parameters defined:</description>
    </item>
    <item>
      <title>OTel Collector and Metrics</title>
      <link>http://localhost:1313/20-observability/22-external/226-otel_collector_metrics/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/226-otel_collector_metrics/index.html</guid>
      <description>Now, let’s add Metrics to our environment. Kong has supported Prometheus-based metrics for a long time through the Prometheus Plugin. In an OpenTelemetry configuration scenario the plugin is an option, where we could add a specific “prometheusreceiver” to the collector configuration. The receiver is responsible for scraping the Data Plane’s Status API, which, by default, is configured with the :8100/metrics endpoint.&#xA;You can check the port with:&#xA;kubectl get pod -o yaml $(kubectl get pod -n kong -o json | jq -r &#39;.items[].metadata | select(.name | startswith(&#34;dataplane-&#34;))&#39; | jq -r &#39;.name&#39;) -n kong | yq &#39;.spec.containers[].env[] | select(.name == &#34;KONG_STATUS_LISTEN&#34;)&#39; Expected result:</description>
    </item>
    <item>
      <title>OTel Collector and Logs</title>
      <link>http://localhost:1313/20-observability/22-external/227-otel_collector_logs/index.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/20-observability/22-external/227-otel_collector_logs/index.html</guid>
      <description>We still need to add logs to our environment where Loki has been deployed. To inject Kong Gateway’s Access Logs, we can use a Log Processing plugin Kong Gateway provides, for example the TCP Log Plugin.&#xA;Hit the port to make sure Loki is ready to accept requests:&#xA;curl http://localhost:3100/ready New collector configuration cat &gt; otelcollector.yaml &lt;&lt; &#39;EOF&#39; apiVersion: opentelemetry.io/v1beta1 kind: OpenTelemetryCollector metadata: name: collector-kong namespace: opentelemetry-operator-system spec: image: otel/opentelemetry-collector-contrib:0.132.2 serviceAccount: collector mode: deployment config: receivers: otlp: protocols: grpc: endpoint: 0.0.0.0:4317 http: endpoint: 0.0.0.0:4318 prometheus: config: scrape_configs: - job_name: &#39;otel-collector&#39; scrape_interval: 5s kubernetes_sd_configs: - role: pod scheme: http tls_config: ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt authorization: credentials_file: /var/run/secrets/kubernetes.io/serviceaccount/token metrics_path: /metrics relabel_configs: - source_labels: [__meta_kubernetes_namespace] action: keep regex: &#34;kong&#34; - source_labels: [__meta_kubernetes_pod_name] action: keep regex: &#34;dataplane-(.+)&#34; - source_labels: [__meta_kubernetes_pod_container_name] action: keep regex: &#34;proxy&#34; - source_labels: [__meta_kubernetes_pod_container_port_number] action: keep regex: &#34;8100&#34; tcplog: listen_address: 0.0.0.0:54525 operators: - type: json_parser exporters: otlphttp/jaeger: endpoint: http://jaeger-collector.jaeger:4318 otlphttp/prometheus: endpoint: http://prometheus-kube-prometheus-prometheus.prometheus:9090/api/v1/otlp otlphttp/loki: endpoint: http://loki.loki:3100/otlp prometheus: endpoint: 0.0.0.0:8889 #debug: # verbosity: detailed service: pipelines: traces: receivers: [otlp] exporters: [otlphttp/jaeger] metrics: receivers: [prometheus] exporters: [otlphttp/prometheus, prometheus] logs: receivers: [tcplog] exporters: [otlphttp/loki] EOF The declaration has critical parameters defined:</description>
    </item>
  </channel>
</rss>